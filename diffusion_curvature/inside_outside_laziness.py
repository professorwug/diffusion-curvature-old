# AUTOGENERATED! DO NOT EDIT! File to edit: ../02b_signed_inside_outside_curvature.ipynb.

# %% auto 0
__all__ = ['inside_outside_laziness', 'inside_outside_laziness_v2']

# %% ../02b_signed_inside_outside_curvature.ipynb 3
from tqdm.notebook import trange
def inside_outside_laziness(A, diffusion_powers = 8, aperture = 80, neighborhood = 1, dynamically_adjusting_neighborhood = False, smoothing=1, verbose=True, proportion_inside = 4):
    """Take a localized measure of diffusion laziness, with diffusion restricted to with the given aperture. Estimates curvature.

    Parameters
    ----------
    A : ndarray
        Affinity matrix of data (non-row normalized)
    diffusion_powers : int, optional
        The number of matrix powers to raise the diffusion operature, by default 8
    aperture : int, optional
        The number of nearest neighbors to which to limit the diffusion operator, by default 80
    neighborhood : int, optional
        The number of nearest neighbors of a point to use calculating laziness, by default 1
    dynamically_adjusting_neighborhood : bool, optional
        Whether the aperture and neighborhood should be based on thresholds derived over the dataset (False) or 
        should expand to create the designated number of neighbors everywhere in the dataset (if True), by default False
    smoothing : int, optional
        Number of iterations of diffusion averaging to apply to the laziness values before returning, by default 1
    verbose : bool, optional
        Whether to print debugging statements and return extra debugging information, by default True

    Returns
    -------
    list
        Laziness value at each point
    """
    # First, a proof of concept: iterate through every point,
    # Make a sub-diffusion matrix for that point, consisting only of the k neighborhood
    # And calculate the laziness for each value
    ks = []
    # debugging
    inside_measures = []
    outside_measures = []
    list_of_Ps = []
    list_of_idxs = []
    # TODO: This is not very efficient; it fails to reuse the computations in each diffusion matrix, 
    # since each point has a separate matrix. Must reconsider that.
    for i in trange(A.shape[0]):
        # Get the indices of the "aperture" closest points, as measured by the diffusion probabilities
        idxs = np.argsort(A[i])[-aperture:][::-1] # ordered from greatest to least affinity
        # Create a sub-diffusion matrix. The point i should be first, since the unpowered matrix
        # measures affinity
        W_sub = A[idxs][:,idxs]
        degrees = np.diag(1/np.sum(W_sub,axis=1))
        P = degrees @ W_sub
    
        # Create the thresholded P, where the threshold is given by the affinity
        # between point i and the halfway point
        threshold = P[0,aperture//proportion_inside]
        P_thresholded = (P >= threshold).astype(int)

        P_powered = np.linalg.matrix_power(P,diffusion_powers)
        inside_matrix = P_powered * P_thresholded
        inside_measure = np.sum(inside_matrix[0])
        
        outside_matrix = P_powered * np.abs(1 - P_thresholded)
        outside_measure = np.sum(outside_matrix[0])
        
        expected_inside_measure = inside_measure / np.sum(P_thresholded[0])
        expected_outside_measure = outside_measure / (len(P_thresholded) - np.sum(P_thresholded[0]))
        
        k = expected_inside_measure - expected_outside_measure
        ks.append(k)
        list_of_Ps.append(P_powered)
        list_of_idxs.append(idxs)
        inside_measures.append(expected_inside_measure)
        outside_measures.append(expected_outside_measure)
    # Smoothing
    if smoothing is not None:  
        D = np.diag(1/np.sum(A,axis=1))
        P = D @ A 
        P_t = np.linalg.matrix_power(P,smoothing)
        ks_smoothed = P_t @ np.array(ks)[:,None]
        ks = ks_smoothed.squeeze()
        inside_measures = (P_t @ np.array(inside_measures)[:,None]).squeeze()
        outside_measures = (P_t @ np.array(outside_measures)[:,None]).squeeze()
        ks_smoothy = inside_measures - outside_measures
    if verbose:
        return ks_smoothy, inside_measures, outside_measures, list_of_Ps, list_of_idxs
    return ks


# %% ../02b_signed_inside_outside_curvature.ipynb 29
import numpy as np
def inside_outside_laziness_v2(P, diffusion_powers=8, inner_aperture = 20, outer_aperture = 40, smoothing=1, verbose = False, dynamically_adjusting_neighborhood = False, precomputed_powered_P = None, non_lazy_diffusion=False, restrict_diffusion_to_k_neighborhood=None, use_min_threshold = False):
    """Diffusion Laziness Curvature
    Estimates curvature by measuring the amount of mass remaining within an initial neighborhood after t steps of diffusion. Akin to measuring the laziness of a random walk after t steps.

    Parameters
    ----------
    P : n x n ndarray
        The diffusion matrix of the graph
    diffusion_powers : int, optional
        Number of steps of diffusion to take before measuring the laziness, by default 8
    aperture : int, optional
        The size of the initial neighborhood, from which the percentage of mass remaining in this neighborhood is calculated, by default 20
    smoothing : int, optional
        Amount of smoothing to apply. Currently works by multiplying the raw laziness values with the diffusion operator, as a kind of iterated weighted averaging; by default 1
    verbose : bool, optional
        Print diagnostics, by default False
    return_density : bool, optional
        Return the number of neighbors each point shares, by default False
    dynamically_adjusting_neighborhood : bool, optional
        Whether to give each point the same initial neighborhood size, by default False
    precomputed_powered_P : ndarray, optional
        Optionally pass a precomputed powered diffusion operator, to speed up computation, by default None
    avg_transition_probability: bool, default True
        Use the definition of diffusion curvature in which the summed transition probabilities are divided by the total number of points in the aperture neighborhood.
        As a result, gives not the summed "return probability within the neighborhood" but the average return probability to each point in the aperture neighborhood.
        This formulation of diffusion curvature was used in proof given in our NeurIPS 2022 paper.

    Returns
    -------
    length n array
        The laziness curvature values for each point
    """
    # the aperture sets the size of the one-hop neighborhood 
    # the aperture parameter is the average number of neighbors to include, based off of the sorted diffusion values
    # Set thresholds as the kth largest diffusion value, presumed to be held by the kth nearest neighbor.
    # The curvature donut: an inner hole and an outer hole. The inner aperture determines
    # the size of the inner hole
    # The outer threshold determines the size of the outer hole
    inner_thresholds = np.partition(P,-inner_aperture)[:,-inner_aperture]
    outer_thresholds = np.partition(P,-outer_aperture)[:,-outer_aperture]
    P_threshold_inner = np.mean(inner_thresholds) 
    P_thresholded_inner = (P >= P_threshold_inner).astype(int)
    
    P_threshold_outer = np.mean(outer_thresholds) 
    P_thresholded_outer = (P >= P_threshold_outer).astype(int) - P_thresholded_inner
    
    if precomputed_powered_P is not None:
        P_powered = precomputed_powered_P
    else:
        P_powered = np.linalg.matrix_power(P,diffusion_powers)
    
    # take the diffusion probs of the neighborhood
    inside_laziness = np.sum(P_powered * P_thresholded_inner,axis=1)    
    local_density = np.sum(P_thresholded_inner,axis=1)
    # divide by the number of neighbors diffused to
    local_density[local_density==0]=1
    expected_inside_laziness = inside_laziness / local_density
    # repeat for outside laziness
    outside_laziness = np.sum(P_powered * P_thresholded_outer,axis=1)    
    local_density = np.sum(P_thresholded_outer,axis=1)
    # divide by the number of neighbors diffused to
    local_density[local_density==0]=1
    expected_outside_laziness = outside_laziness / local_density
    
#     ks = expected_inside_laziness - expected_outside_laziness
    
    if smoothing: # TODO there are probably more intelligent ways to do this smoothing
        # Local averaging to counter the effects local density
        if verbose: print("Applying smoothing...")
        smoothing_P_powered = np.linalg.matrix_power(P,smoothing)
        expected_inside_laziness = (smoothing_P_powered @ expected_inside_laziness[:,None]).squeeze()
        expected_outside_laziness = (smoothing_P_powered @ expected_outside_laziness[:,None]).squeeze()
        ks = expected_inside_laziness - expected_outside_laziness
    return ks, expected_inside_laziness, expected_outside_laziness

